# üéì Guide : Ajouter Votre Mod√®le

Guide complet pour les √©tudiants qui veulent ajouter leur propre mod√®le de d√©tection de d√©pression.

---

## üìã Vue d'Ensemble

L'API utilise une **architecture multi-mod√®les** qui permet √† chaque √©tudiant d'ajouter son propre mod√®le sans conflit avec les autres.

### Principe

Chaque mod√®le est dans son propre dossier :
```
app/services/
‚îú‚îÄ‚îÄ yansnet_llm/          # Mod√®le de l'√©quipe YANSNET
‚îú‚îÄ‚îÄ votre_modele/         # VOTRE mod√®le ici
‚îî‚îÄ‚îÄ autre_etudiant/       # Mod√®le d'un autre √©tudiant
```

---

## üöÄ √âtapes pour Ajouter Votre Mod√®le

### 1. Cr√©er la Structure

```bash
# Cr√©er votre dossier
mkdir app/services/votre_nom_modele

# Cr√©er les fichiers n√©cessaires
touch app/services/votre_nom_modele/__init__.py
touch app/services/votre_nom_modele/votre_nom_model.py
touch app/services/votre_nom_modele/requirements.txt
```

### 2. Impl√©menter l'Interface

Cr√©er `app/services/votre_nom_modele/votre_nom_model.py` :

```python
"""
Votre mod√®le de d√©tection de d√©pression
"""
from typing import Dict, Any, List
from app.core.base_model import BaseDepressionModel
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class VotreNomModel(BaseDepressionModel):
    """
    Description de votre mod√®le.
    
    Exemple: Mod√®le GCN avec embeddings BERT
    """
    
    # ========================================================================
    # PROPRI√âT√âS OBLIGATOIRES
    # ========================================================================
    
    @property
    def model_name(self) -> str:
        """Nom unique (format: nom_equipe-type)"""
        return "votre_nom-gcn"  # Exemple: "dupont-gcn", "martin-lstm"
    
    @property
    def model_version(self) -> str:
        """Version du mod√®le"""
        return "1.0.0"
    
    @property
    def author(self) -> str:
        """Votre nom ou √©quipe"""
        return "Votre Nom"
    
    @property
    def description(self) -> str:
        """Description courte"""
        return "Mod√®le GCN avec embeddings BERT pour d√©tection de d√©pression"
    
    @property
    def tags(self) -> List[str]:
        """Tags pour cat√©goriser"""
        return ["gcn", "bert", "graph-neural-network"]
    
    # ========================================================================
    # INITIALISATION
    # ========================================================================
    
    def __init__(self):
        """
        Initialisez votre mod√®le ici.
        
        Chargez les poids, configurez les param√®tres, etc.
        """
        try:
            # Exemple: charger un mod√®le PyTorch
            # self.model = torch.load('path/to/model.pt')
            # self.tokenizer = AutoTokenizer.from_pretrained('bert-base')
            
            logger.info(f"‚úì {self.model_name} initialis√©")
            self._initialized = True
            
        except Exception as e:
            logger.error(f"‚úó Erreur d'initialisation: {e}")
            self._initialized = False
            raise
    
    # ========================================================================
    # M√âTHODE OBLIGATOIRE: PREDICT
    # ========================================================================
    
    def predict(self, text: str, **kwargs) -> Dict[str, Any]:
        """
        Pr√©dit si le texte indique de la d√©pression.
        
        Args:
            text: Texte √† analyser
            **kwargs: Param√®tres additionnels (optionnels)
        
        Returns:
            Dict avec AU MINIMUM:
            {
                "prediction": "D√âPRESSION" ou "NORMAL",
                "confidence": float (0.0 √† 1.0),
                "severity": "Aucune"|"Faible"|"Moyenne"|"√âlev√©e"|"Critique",
                "reasoning": str (optionnel)
            }
        """
        if not self._initialized:
            raise RuntimeError(f"{self.model_name} non initialis√©")
        
        try:
            # VOTRE CODE ICI
            # Exemple:
            # 1. Pr√©traiter le texte
            # processed = self.preprocess(text)
            
            # 2. G√©n√©rer embeddings
            # embeddings = self.get_embeddings(processed)
            
            # 3. Pr√©dire avec votre mod√®le
            # output = self.model(embeddings)
            # prediction = "D√âPRESSION" if output > 0.5 else "NORMAL"
            # confidence = float(output)
            
            # Pour l'exemple, retournons un r√©sultat fictif
            prediction = "NORMAL"
            confidence = 0.75
            severity = "Aucune"
            reasoning = "Analyse bas√©e sur GCN avec embeddings BERT"
            
            return {
                "prediction": prediction,
                "confidence": confidence,
                "severity": severity,
                "reasoning": reasoning
            }
            
        except Exception as e:
            logger.error(f"Erreur de pr√©diction: {e}")
            raise
    
    # ========================================================================
    # M√âTHODE OPTIONNELLE: BATCH_PREDICT
    # ========================================================================
    
    def batch_predict(self, texts: List[str], **kwargs) -> List[Dict[str, Any]]:
        """
        Pr√©diction batch (optionnel, mais recommand√© pour performance).
        
        Si non impl√©ment√©, l'impl√©mentation par d√©faut appelle predict()
        pour chaque texte.
        """
        # Impl√©mentation par d√©faut (peut √™tre optimis√©e)
        return [self.predict(text, **kwargs) for text in texts]
        
        # OU impl√©mentation optimis√©e:
        # results = []
        # embeddings = self.batch_get_embeddings(texts)
        # outputs = self.model(embeddings)
        # for output in outputs:
        #     results.append({...})
        # return results
```

### 3. Cr√©er __init__.py

Cr√©er `app/services/votre_nom_modele/__init__.py` :

```python
"""
Votre mod√®le
"""
from .votre_nom_model import VotreNomModel

__all__ = ['VotreNomModel']
```

### 4. Ajouter les D√©pendances

Cr√©er `app/services/votre_nom_modele/requirements.txt` :

```txt
# D√©pendances sp√©cifiques √† votre mod√®le
torch>=2.0.0
torch-geometric>=2.3.0
transformers>=4.30.0
scikit-learn>=1.3.0
```

### 5. Enregistrer le Mod√®le

Modifier `app/main.py` pour enregistrer votre mod√®le :

```python
@app.on_event("startup")
async def startup_event():
    # ... code existant ...
    
    # Ajouter votre mod√®le
    try:
        from app.services.votre_nom_modele import VotreNomModel
        registry.register(VotreNomModel())
        logger.info("‚úì Votre mod√®le enregistr√©")
    except Exception as e:
        logger.error(f"‚úó Erreur: {e}")
```

### 6. Installer et Tester

```bash
# Installer vos d√©pendances
pip install -r app/services/votre_nom_modele/requirements.txt

# Lancer l'API
uvicorn app.main:app --reload

# Tester votre mod√®le
curl http://localhost:8000/api/v1/models

curl -X POST "http://localhost:8000/api/v1/predict?model_name=votre_nom-gcn" \
  -H "Content-Type: application/json" \
  -d '{"text": "I feel sad"}'
```

---

## üìù Exemple Complet : Mod√®le GCN

Voici un exemple complet d'un mod√®le GCN :

```python
"""
Mod√®le GCN de Jean Dupont
"""
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from typing import Dict, Any, List
from app.core.base_model import BaseDepressionModel
from app.utils.logger import setup_logger

logger = setup_logger(__name__)


class DupontGCNModel(BaseDepressionModel):
    """Mod√®le GCN avec embeddings BERT"""
    
    @property
    def model_name(self) -> str:
        return "dupont-gcn"
    
    @property
    def model_version(self) -> str:
        return "1.0.0"
    
    @property
    def author(self) -> str:
        return "Jean Dupont"
    
    @property
    def description(self) -> str:
        return "GCN avec BERT embeddings et attention mechanism"
    
    @property
    def tags(self) -> List[str]:
        return ["gcn", "bert", "attention", "graph-neural-network"]
    
    def __init__(self, model_path: str = "./models/dupont_gcn.pt"):
        """Initialise le mod√®le GCN"""
        try:
            # Charger BERT
            self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
            self.bert = AutoModel.from_pretrained("bert-base-uncased")
            
            # Charger le mod√®le GCN
            self.gcn_model = torch.load(model_path)
            self.gcn_model.eval()
            
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            self.bert.to(self.device)
            self.gcn_model.to(self.device)
            
            logger.info(f"‚úì {self.model_name} initialis√© sur {self.device}")
            self._initialized = True
            
        except Exception as e:
            logger.error(f"‚úó Erreur d'initialisation: {e}")
            self._initialized = False
            raise
    
    def get_embeddings(self, text: str) -> torch.Tensor:
        """G√©n√®re les embeddings BERT"""
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        ).to(self.device)
        
        with torch.no_grad():
            outputs = self.bert(**inputs)
            embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token
        
        return embeddings
    
    def predict(self, text: str, **kwargs) -> Dict[str, Any]:
        """Pr√©dit avec le GCN"""
        if not self._initialized:
            raise RuntimeError(f"{self.model_name} non initialis√©")
        
        try:
            # 1. G√©n√©rer embeddings
            embeddings = self.get_embeddings(text)
            
            # 2. Pr√©dire avec GCN
            with torch.no_grad():
                output = self.gcn_model(embeddings)
                probs = torch.softmax(output, dim=1)
                pred_class = torch.argmax(probs, dim=1).item()
                confidence = probs[0, pred_class].item()
            
            # 3. Interpr√©ter
            prediction = "D√âPRESSION" if pred_class == 1 else "NORMAL"
            
            # D√©terminer s√©v√©rit√©
            if prediction == "D√âPRESSION":
                if confidence > 0.9:
                    severity = "√âlev√©e"
                elif confidence > 0.7:
                    severity = "Moyenne"
                else:
                    severity = "Faible"
            else:
                severity = "Aucune"
            
            return {
                "prediction": prediction,
                "confidence": float(confidence),
                "severity": severity,
                "reasoning": f"Analyse GCN avec confiance {confidence:.2%}"
            }
            
        except Exception as e:
            logger.error(f"Erreur de pr√©diction: {e}")
            raise
```

---

## üß™ Tests

Cr√©er `tests/test_votre_modele.py` :

```python
"""
Tests pour votre mod√®le
"""
import pytest
from app.services.votre_nom_modele import VotreNomModel


def test_model_initialization():
    """Test d'initialisation"""
    model = VotreNomModel()
    assert model.model_name == "votre_nom-gcn"
    assert model.model_version == "1.0.0"


def test_model_predict():
    """Test de pr√©diction"""
    model = VotreNomModel()
    result = model.predict("I feel sad")
    
    assert "prediction" in result
    assert "confidence" in result
    assert "severity" in result
    assert result["prediction"] in ["D√âPRESSION", "NORMAL"]
    assert 0 <= result["confidence"] <= 1


def test_model_batch_predict():
    """Test de pr√©diction batch"""
    model = VotreNomModel()
    texts = ["I'm happy", "I feel sad"]
    results = model.batch_predict(texts)
    
    assert len(results) == 2
    for result in results:
        assert "prediction" in result
```

---

## üìã Checklist

Avant de push votre mod√®le :

- [ ] Dossier cr√©√© : `app/services/votre_nom_modele/`
- [ ] Classe impl√©mente `BaseDepressionModel`
- [ ] M√©thode `predict()` retourne le bon format
- [ ] `requirements.txt` avec vos d√©pendances
- [ ] Mod√®le enregistr√© dans `app/main.py`
- [ ] Tests √©crits et passent
- [ ] Documentation ajout√©e (docstrings)
- [ ] Pas de secrets dans le code (cl√©s API, etc.)

---

## ü§ù Bonnes Pratiques

### Nommage

- **Nom du mod√®le** : `nom_equipe-type` (ex: `dupont-gcn`, `martin-lstm`)
- **Dossier** : `app/services/nom_equipe_type/`
- **Classe** : `NomEquipeTypeModel` (ex: `DupontGCNModel`)

### Performance

- Impl√©menter `batch_predict()` pour optimiser
- Utiliser `@torch.no_grad()` pour l'inf√©rence
- Charger le mod√®le une seule fois (dans `__init__`)

### Erreurs

- Toujours logger les erreurs
- Retourner un r√©sultat m√™me en cas d'erreur
- Ne pas faire crasher l'API

### Documentation

- Docstrings claires
- Expliquer les param√®tres
- Donner des exemples

---

## ‚ùì FAQ

### Q: Mon mod√®le utilise PyTorch, un autre utilise TensorFlow. Probl√®me ?

**R:** Non ! Chaque mod√®le a ses propres d√©pendances dans son `requirements.txt`.

### Q: Comment g√©rer les fichiers de mod√®le volumineux ?

**R:** 
1. Ne PAS les commit dans git
2. Les stocker ailleurs (Google Drive, S3)
3. T√©l√©charger au premier lancement
4. Ajouter au `.gitignore`

### Q: Puis-je utiliser des donn√©es externes ?

**R:** Oui, mais :
- Documenter la source
- Respecter les licences
- Ne pas commit les donn√©es volumineuses

### Q: Mon mod√®le est lent, que faire ?

**R:**
- Impl√©menter `batch_predict()` optimis√©
- Utiliser GPU si disponible
- Cacher les r√©sultats fr√©quents
- Optimiser le preprocessing

---

## üìû Support

- **Documentation** : Voir les autres docs dans `docs/`
- **Exemple** : Regarder `app/services/yansnet_llm/`
- **Issues** : Cr√©er une issue GitHub
- **Questions** : Demander √† l'√©quipe

---

**Bon courage pour votre mod√®le ! üöÄ**
